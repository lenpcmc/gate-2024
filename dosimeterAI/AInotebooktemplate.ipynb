{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4ad646",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 33\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03mBoston housing dataset: https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mData has white spaces, not commas.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "__author__ = \"Sreenivas Bhattiprolu\"\n",
    "__license__ = \"Feel free to copy, I appreciate if you acknowledge Python for Microscopists\"\n",
    "\n",
    "# https://youtu.be/2yhLEx2FKoY\n",
    "\n",
    "\"\"\"\n",
    "Boston housing dataset: https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\n",
    "Data has white spaces, not commas.\n",
    "\n",
    "1. CRIM      per capita crime rate by town\n",
    "    2. ZN        proportion of residential land zoned for lots over \n",
    "                 25,000 sq.ft.\n",
    "    3. INDUS     proportion of non-retail business acres per town\n",
    "    4. CHAS      Charles River dummy variable (= 1 if tract bounds \n",
    "                 river; 0 otherwise)\n",
    "    5. NOX       nitric oxides concentration (parts per 10 million)\n",
    "    6. RM        average number of rooms per dwelling\n",
    "    7. AGE       proportion of owner-occupied units built prior to 1940\n",
    "    8. DIS       weighted distances to five Boston employment centres\n",
    "    9. RAD       index of accessibility to radial highways\n",
    "    10. TAX      full-value property-tax rate per $10,000\n",
    "    11. PTRATIO  pupil-teacher ratio by town\n",
    "    12. B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks \n",
    "                 by town\n",
    "    13. LSTAT    % lower status of the population\n",
    "    14. MEDV     Median value of owner-occupied homes in $1000's\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load data and arrange into Pandas dataframe\n",
    "df = read_csv(\"housing_data/housing_data_for_regression.csv\", delim_whitespace=True, header=None)\n",
    "\n",
    "feature_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', \n",
    "                 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "\n",
    "\n",
    "df.columns = feature_names\n",
    "print(df.head())\n",
    "\n",
    "df = df.rename(columns={'MEDV': 'PRICE'})\n",
    "print(df.describe())\n",
    "\n",
    "\n",
    "#Split into features and target (Price)\n",
    "X = df.drop('PRICE', axis = 1)\n",
    "y = df['PRICE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 20)\n",
    "\n",
    "\n",
    "#Scale data, otherwise model will fail.\n",
    "#Standardize features by removing the mean and scaling to unit variance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# define the model\n",
    "#Experiment with deeper and wider networks\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=13, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "#Output layer\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, validation_split=0.2, epochs =100)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc = history.history['mean_absolute_error']\n",
    "val_acc = history.history['val_mean_absolute_error']\n",
    "plt.plot(epochs, acc, 'y', label='Training MAE')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation MAE')\n",
    "plt.title('Training and validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "############################################\n",
    "#Predict on test data\n",
    "predictions = model.predict(X_test_scaled[:5])\n",
    "print(\"Predicted values are: \", predictions)\n",
    "print(\"Real values are: \", y_test[:5])\n",
    "##############################################\n",
    "\n",
    "#Comparison with other models..\n",
    "#Neural network - from the current code\n",
    "mse_neural, mae_neural = model.evaluate(X_test_scaled, y_test)\n",
    "print('Mean squared error from neural net: ', mse_neural)\n",
    "print('Mean absolute error from neural net: ', mae_neural)\n",
    "\n",
    "######################################################################\n",
    "#Linear regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "### Linear regression\n",
    "lr_model = linear_model.LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "print('Mean squared error from linear regression: ', mse_lr)\n",
    "print('Mean absolute error from linear regression: ', mae_lr)\n",
    "\n",
    "############################################################\n",
    "### Decision tree\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train_scaled, y_train)\n",
    "y_pred_tree = tree.predict(X_test_scaled)\n",
    "mse_dt = mean_squared_error(y_test, y_pred_tree)\n",
    "mae_dt = mean_absolute_error(y_test, y_pred_tree)\n",
    "print('Mean squared error using decision tree: ', mse_dt)\n",
    "print('Mean absolute error using decision tree: ', mae_dt)\n",
    "\n",
    "##############################################\n",
    "#Random forest.\n",
    "#Increase number of tress and see the effect\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators = 30, random_state=30)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_RF = model.predict(X_test_scaled)\n",
    "\n",
    "mse_RF = mean_squared_error(y_test, y_pred_RF)\n",
    "mae_RF = mean_absolute_error(y_test, y_pred_RF)\n",
    "print('Mean squared error using Random Forest: ', mse_RF)\n",
    "print('Mean absolute error Using Random Forest: ', mae_RF)\n",
    "\n",
    "#Feature ranking...\n",
    "import pandas as pd\n",
    "feature_list = list(X.columns)\n",
    "feature_imp = pd.Series(model.feature_importances_, index=feature_list).sort_values(ascending=False)\n",
    "print(feature_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eef0dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
